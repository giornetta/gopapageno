package gopapageno

type AOPParser struct {
	*OPParser
}

func NewAOPParser(g *Grammar, src []byte, opts *RunOptions) *AOPParser {
	p := &AOPParser{
		OPParser: &OPParser{
			g:                 g,
			concurrency:       opts.Concurrency,
			reductionStrategy: opts.ReductionStrategy,
			workers:           make([]*oppWorker, opts.Concurrency),
			results:           make([]*OPPStack, opts.Concurrency),
		},
	}

	srcLen := len(src)
	stackPoolBaseSize := stacksCountFactored[*Token](src, opts)
	ntPoolBaseSize := srcLen / opts.AvgTokenLength / p.concurrency

	// Initialize memory pools for stacks.
	p.pools.stacks = make([]*Pool[stack[*Token]], p.concurrency)

	// Initialize pools to hold pointers to tokens generated by the reduction steps.
	p.pools.nonterminals = make([]*Pool[Token], p.concurrency)

	stackMult := 1.0
	if stackPoolBaseSize == 0 {
		stackMult = 1.0 - (0.999 * opts.ParallelFactor)
	}

	for thread := 0; thread < p.concurrency; thread++ {
		p.pools.stacks[thread] = NewPool(stackPoolBaseSize+1, WithConstructor(newStackFactory[*Token](stackMult)))
		p.pools.nonterminals[thread] = NewPool[Token](ntPoolBaseSize)
	}

	// If reduction is sweep or mixed, we create another stack and input for the final pass.
	if p.concurrency > 1 && (p.reductionStrategy == ReductionSweep || p.reductionStrategy == ReductionMixed) {
		inputPoolBaseSize := stacksCount[Token](src, p.concurrency, opts.AvgTokenLength)

		p.pools.sweepInput = NewPool(inputPoolBaseSize, WithConstructor(newStack[Token]))
		p.pools.sweepStack = NewPool(stackPoolBaseSize+1, WithConstructor(newStackFactory[*Token](stackMult)))
	}

	for thread := 0; thread < p.concurrency; thread++ {
		p.workers[thread] = &oppWorker{
			parser: p.OPParser,
			id:     thread,
			ntPool: p.pools.nonterminals[thread],
		}
	}

	return p
}
